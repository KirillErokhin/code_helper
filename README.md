# Code Helper с использованием Gradio и Qwen

Этот проект реализует помощника для работы с кодом, используя [Gradio](https://www.gradio.app/) для интерфейса и модель [Qwen](https://huggingface.co/Qwen) для генерации кода. Помощник предназначен для помощи в программировании и генерирует код с комментариями.

## Возможности

- **Интерфейс на основе Gradio**: Простое веб-приложение для взаимодействия с помощником.
- **Модель Qwen**: Предобученная языковая модель для помощи в написании кода с комментариями.
- **Настраиваемые параметры**: Возможность контролировать количество генерируемых токенов, температуру, и другие параметры через интерфейс.

## Структура проекта

- **`model.pipeline`**: Содержит определения модели и токенизатора, которые загружаются и используются для генерации ответов на основе `Qwen2-7B-Instruct`.
- **Интерфейс на основе Gradio**: Предоставляет интерактивное окно чата, где пользователи могут отправлять запросы, связанные с программированием, и получать ответы с предложениями кода.
- **Поддержка Docker**: Включает файлы `Dockerfile` и `docker-compose.yml` для контейнеризации и запуска с поддержкой GPU через NVIDIA runtime.

## Как это работает

Приложение обрабатывает ввод пользователя, передавая его в языковую модель. Модель генерирует предложения по коду с комментариями, которые отображаются через интерфейс Gradio.

### Основные компоненты:

1. **Интерфейс Gradio** (`app.py`):
   - Этот скрипт настраивает интерфейс чата Gradio, позволяя пользователям взаимодействовать с моделью.
   - В интерфейсе присутствуют слайдеры для настройки параметров генерации, таких как количество токенов, температура, и топ-K выборка.

2. **Загрузка модели** (`model.pipeline`):
   - Загружает языковую модель Qwen с 4-битной квантовой точностью для уменьшения использования памяти, сохраняя при этом высокую точность.
   - Использует специальный системный промт для настройки модели на помощь в программировании.

3. **Docker**:
   - **Dockerfile**: Определяет среду для запуска приложения, включая Python 3.10 и необходимые зависимости.
   - **docker-compose.yml**: Настраивает запуск приложения с поддержкой GPU, пробрасывая необходимые порты (например, 7860 для Gradio).

## Установка

### Требования

- **Python**: Версия 3.10 или выше.
- **Docker**: Для контейнеризированного запуска с поддержкой GPU.

### Шаги установки

1. **Клонируйте репозиторий**:

   ```bash
   git clone https://github.com/kirillerokhin/code-helper.git
   cd code-helper
   ```

2. **Создайте окружение и установите зависимости**:

   Если вы планируете запускать приложение локально, сначала создайте окружение, а затем установите необходимые пакеты Python:

   ```bash
   pip install -r requirements.txt
   ```

3. **Запуск с Docker**:

   Постройте и запустите приложение в контейнере с поддержкой GPU:

   ```bash
   docker-compose up --build
   ```

   Это запустит интерфейс Gradio на порту `7860`. Откройте его в браузере по адресу `http://localhost:7860`.

### Локальный запуск

Чтобы запустить приложение без Docker:

```bash
python3 main.py
```

Интерфейс Gradio будет доступен через ваш браузер.

## Использование

- Откройте веб-интерфейс и введите запрос, связанный с программированием.
- Настройте параметры модели, такие как количество токенов или температура, для кастомизации ответа.
- Помощник сгенерирует код, которые будут отображены в чате.

## Пример запроса

```
Напиши функцию на Python для реверса списка и добавь комментарии к каждому шагу.
```

**Сгенерированный ответ**:
```python
def reverse_list(lst):
    """
    Реверсирует переданный список.

    Параметры:
    lst (list): Список, который нужно реверсировать.

    Возвращает:
    list: Новый список с элементами в обратном порядке.
    """
    return lst[::-1]
```

## Настройка

- Вы можете изменить системный промт в Gradio, чтобы настроить поведение модели.
- Для изменения портов или параметров контейнера отредактируйте файл `docker-compose.yml`.